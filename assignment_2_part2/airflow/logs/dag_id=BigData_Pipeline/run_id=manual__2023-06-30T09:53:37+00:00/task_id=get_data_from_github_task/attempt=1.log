[2023-06-30T09:53:46.941+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: BigData_Pipeline.get_data_from_github_task manual__2023-06-30T09:53:37+00:00 [queued]>
[2023-06-30T09:53:46.949+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: BigData_Pipeline.get_data_from_github_task manual__2023-06-30T09:53:37+00:00 [queued]>
[2023-06-30T09:53:46.949+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-30T09:53:46.962+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): get_data_from_github_task> on 2023-06-30 09:53:37+00:00
[2023-06-30T09:53:46.967+0000] {standard_task_runner.py:57} INFO - Started process 3744 to run task
[2023-06-30T09:53:46.971+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'BigData_Pipeline', 'get_data_from_github_task', 'manual__2023-06-30T09:53:37+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmp1gt3a7kg']
[2023-06-30T09:53:46.972+0000] {standard_task_runner.py:85} INFO - Job 26: Subtask get_data_from_github_task
[2023-06-30T09:53:46.987+0000] {logging_mixin.py:149} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-06-30T09:53:47.028+0000] {task_command.py:410} INFO - Running <TaskInstance: BigData_Pipeline.get_data_from_github_task manual__2023-06-30T09:53:37+00:00 [running]> on host 656f1a73f746
[2023-06-30T09:53:47.123+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='BigData_Pipeline' AIRFLOW_CTX_TASK_ID='get_data_from_github_task' AIRFLOW_CTX_EXECUTION_DATE='2023-06-30T09:53:37+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-30T09:53:37+00:00'
[2023-06-30T09:53:47.439+0000] {logging_mixin.py:149} INFO - response: {'date': '20150723', 'plain_text': "Yes, thanks for your question.\nWe have not broken out specifically apparel, but we're super excited about that business.\nIt's growing very well.\nWe like our position in it.\nWe think our website is very, very atune to selling online.\nSo we're very happy with that.\nIt is a big business for us, not only in North America but also Internationally.\nSo you mentioned a couple other consumables categories.\nI will say we are very happy in our consumables and hard line categories as well.\nWe drive a lot of repeat business with things like Prime Pantry and subscribe and Save and others.\nSo very happy with the EGM business as a whole.\nSure.\nLet me start with the first question on international media and EGM.\nI think we're seeing similar trends in both geographies, both segments that EGM growth is much -- is very strong.\nMedia growth has been consistent for the last four quarters.\nWe do like the work being done by the media teams.\nThere's a lot of pipeline of invention, things like Prime Instant Video, Prime Music, all feed the Prime pipeline and Prime ecosystem, if you will.\nThey work great with our devices, by the way.\nAnd they drive other non-media sales.\nSo they're very tied together, although certainly the EGM is outpacing the media segment or excuse me, media businesses right now.\nOn transportation costs, not a lot to add there.\nAgain, we are -- we have a combination of doing our own shipping and using third party carriers.\nSo the rate increases are staged and we see those quite frequently, nothing to add there.\nOn the FCs and whether we would expand or build new, I think we're looking to always to get the most out of the fulfillment centers that we have.\nAnd as we need new facilities, we place them closer and closer to customers.\nSo that can have its benefits as well.\nNot much more to add on that one.\n", 'ticker': 'AMZN', 'company_name': 'Amazon.com, Inc.'}, type: <class 'dict'>
[2023-06-30T09:53:47.439+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-06-30T09:53:47.449+0000] {taskinstance.py:1350} INFO - Marking task as SUCCESS. dag_id=BigData_Pipeline, task_id=get_data_from_github_task, execution_date=20230630T095337, start_date=20230630T095346, end_date=20230630T095347
[2023-06-30T09:53:47.503+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-30T09:53:47.535+0000] {taskinstance.py:2651} INFO - 1 downstream tasks scheduled from follow-on schedule check
