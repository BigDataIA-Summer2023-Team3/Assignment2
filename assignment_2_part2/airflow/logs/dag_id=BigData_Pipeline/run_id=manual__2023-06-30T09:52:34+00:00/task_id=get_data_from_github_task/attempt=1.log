[2023-06-30T09:52:44.975+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: BigData_Pipeline.get_data_from_github_task manual__2023-06-30T09:52:34+00:00 [queued]>
[2023-06-30T09:52:44.983+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: BigData_Pipeline.get_data_from_github_task manual__2023-06-30T09:52:34+00:00 [queued]>
[2023-06-30T09:52:44.983+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-30T09:52:44.996+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): get_data_from_github_task> on 2023-06-30 09:52:34+00:00
[2023-06-30T09:52:45.001+0000] {standard_task_runner.py:57} INFO - Started process 3664 to run task
[2023-06-30T09:52:45.006+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'BigData_Pipeline', 'get_data_from_github_task', 'manual__2023-06-30T09:52:34+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/main.py', '--cfg-path', '/tmp/tmpjy84ofp7']
[2023-06-30T09:52:45.006+0000] {standard_task_runner.py:85} INFO - Job 23: Subtask get_data_from_github_task
[2023-06-30T09:52:45.022+0000] {logging_mixin.py:149} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-06-30T09:52:45.064+0000] {task_command.py:410} INFO - Running <TaskInstance: BigData_Pipeline.get_data_from_github_task manual__2023-06-30T09:52:34+00:00 [running]> on host 656f1a73f746
[2023-06-30T09:52:45.160+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='BigData_Pipeline' AIRFLOW_CTX_TASK_ID='get_data_from_github_task' AIRFLOW_CTX_EXECUTION_DATE='2023-06-30T09:52:34+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-30T09:52:34+00:00'
[2023-06-30T09:52:45.450+0000] {logging_mixin.py:149} INFO - response: {'date': '20150422', 'plain_text': "Thank you, <UNK>.\nI would now like <UNK> <UNK> to give you a few Companywide statistics.\n<UNK>.\nGenerally our collected funds services are really more admin-oriented, not asset management focused in terms of our selling as part of our asset management solution.\nWe do use a collected fund structure to wrap some of our asset management services, but the collected fund line item in our -- on that one schedule in the earnings release is really more attributable to administrative services.\nSo I guess we would like nothing more than -- you know, it would be great if those who were clients of ours on the investment management services side grew their business in the collective side, because that would enhance our service offering.\nBut we're not really focused directly on the collective structure as a market per se.\nNo, we wouldn't even view it as a market per se.\nWe would you it as a product structure that wraps around asset management capabilities that's scalable to particularly the institutional space.\nThank you, <UNK>.\nSo, everybody, in summary we feel that first-quarter 2015 was a solid quarter, created by concentrating our efforts on maintaining highly satisfied clients and growing new business events, controlling costs, and investing in projects that are critical to our future.\nSo looking ahead, we intend to keep our focus on long-term growth in revenue and profits.\nSo that concludes all of our remarks today.\nI'll give you one more chance to ask any questions you might have.\nWell, thank you all for joining us today, and have a good afternoon.\nThanks a lot.\n", 'ticker': 'SEIC', 'company_name': 'SEI Investments Company'}, type: <class 'dict'>
[2023-06-30T09:52:45.451+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-06-30T09:52:45.461+0000] {taskinstance.py:1350} INFO - Marking task as SUCCESS. dag_id=BigData_Pipeline, task_id=get_data_from_github_task, execution_date=20230630T095234, start_date=20230630T095244, end_date=20230630T095245
[2023-06-30T09:52:45.498+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-30T09:52:45.533+0000] {taskinstance.py:2651} INFO - 1 downstream tasks scheduled from follow-on schedule check
